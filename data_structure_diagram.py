#!/usr/bin/env python3
"""
ASCII Art Data Structure Diagram for HTML Search Engine - Part 2
"""

def print_data_structure_diagram():
    """Print ASCII art representation of the data structures."""

    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                        HTML SEARCH ENGINE - PART 2 DATA STRUCTURES                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   HTML FILES    â”‚â”€â”€â”€â–¶â”‚                    HTML INDEXER                            â”‚
â”‚   (Jan.zip)     â”‚    â”‚                                                             â”‚
â”‚                 â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â€¢ aol.html      â”‚    â”‚  â”‚   TOKENIZER     â”‚  â”‚        STOP WORD FILTER          â”‚ â”‚
â”‚ â€¢ bill.html     â”‚    â”‚  â”‚                 â”‚  â”‚                                  â”‚ â”‚
â”‚ â€¢ kitty.html    â”‚    â”‚  â”‚ â€¢ Extract text  â”‚  â”‚ â€¢ Remove: 'a', 'the', 'and'     â”‚ â”‚
â”‚ â€¢ ...           â”‚    â”‚  â”‚ â€¢ Extract URLs  â”‚  â”‚ â€¢ Remove: 'is', 'of', 'to'      â”‚ â”‚
â”‚                 â”‚    â”‚  â”‚ â€¢ Word positionsâ”‚  â”‚ â€¢ Keep: 'web', 'page', 'email'  â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
                                                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              CORE DATA STRUCTURES                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                      â”‚
â”‚  1ï¸âƒ£  DOCUMENT LIST (Hash Map)                                                       â”‚
â”‚      doc_id â”€â”€â–¶ DocumentRecord(doc_id, url, length, unique_words)                  â”‚
â”‚                                                                                      â”‚
â”‚      "./Jan/kitty.html" â”€â”€â–¶ { doc_id: "./Jan/kitty.html"                          â”‚
â”‚                               url: "Jan/kitty.html"                                â”‚
â”‚                               length: 238                                          â”‚
â”‚                               unique_words: 184 }                                  â”‚
â”‚                                                                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚                                                                                      â”‚
â”‚  2ï¸âƒ£  INVERTED INDEX (Hash Map)                                                      â”‚
â”‚      word â”€â”€â–¶ InvertedIndexEntry(word, doc_frequency, postings[])                  â”‚
â”‚                                                                                      â”‚
â”‚      "web" â”€â”€â–¶ { word: "web"                                                       â”‚
â”‚                  document_frequency: 2                                             â”‚
â”‚                  postings: [                                                       â”‚
â”‚                    PostingRecord(                                                  â”‚
â”‚                      doc_id: "./Jan/bill.html"                                     â”‚
â”‚                      term_frequency: 1                                             â”‚
â”‚                      tf_idf: 0.026871                                              â”‚
â”‚                      positions: [77]                                               â”‚
â”‚                    ),                                                               â”‚
â”‚                    PostingRecord(                                                  â”‚
â”‚                      doc_id: "./Jan/kitty.html"                                    â”‚
â”‚                      term_frequency: 2                                             â”‚
â”‚                      tf_idf: 0.023032                                              â”‚
â”‚                      positions: [40, 81]                                           â”‚
â”‚                    )                                                                â”‚
â”‚                  ] }                                                                â”‚
â”‚                                                                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚                                                                                      â”‚
â”‚  3ï¸âƒ£  URL TRACKING (Lists + Hash Map)                                               â”‚
â”‚      url_list: ["mailto:user@site.com", "image.gif", ...]                         â”‚
â”‚      url_status: { "mailto:user@site.com" â”€â”€â–¶ "unvisited" }                       â”‚
â”‚                                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            QUERY PROCESSOR                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                      â”‚
â”‚  ðŸ“ QUERY TYPES:                                                                    â”‚
â”‚                                                                                      â”‚
â”‚  â€¢ Boolean OR:  "cat or dog"     â”€â”€â–¶ Union of document sets                        â”‚
â”‚  â€¢ Boolean AND: "cat and dog"    â”€â”€â–¶ Intersection of document sets                 â”‚
â”‚  â€¢ Boolean NOT: "cat but dog"    â”€â”€â–¶ Difference of document sets                   â”‚
â”‚  â€¢ Phrase:      "\"web page\""     â”€â”€â–¶ Consecutive word positions                    â”‚
â”‚  â€¢ Vector:      "cat dog"        â”€â”€â–¶ Cosine similarity with TF-IDF                 â”‚
â”‚                                                                                      â”‚
â”‚  ðŸ§® TF-IDF CALCULATION:                                                             â”‚
â”‚      TF = term_frequency / document_length                                          â”‚
â”‚      IDF = log(total_documents / document_frequency)                                â”‚
â”‚      TF-IDF = TF Ã— IDF                                                              â”‚
â”‚                                                                                      â”‚
â”‚  ðŸ“Š COSINE SIMILARITY:                                                              â”‚
â”‚      similarity = dot_product(query_vector, doc_vector) /                          â”‚
â”‚                   (||query_vector|| Ã— ||doc_vector||)                              â”‚
â”‚                                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              USER INTERFACES                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚           CONSOLE APP           â”‚                    GUI APP                        â”‚
â”‚                                 â”‚                                                    â”‚
â”‚  â€¢ Interactive query input      â”‚  â€¢ Visual search interface                        â”‚
â”‚  â€¢ Query type display           â”‚  â€¢ Result cards with scores                       â”‚
â”‚  â€¢ Ranked results with scores   â”‚  â€¢ Query type identification                      â”‚
â”‚  â€¢ Support for all query types  â”‚  â€¢ Real-time search                               â”‚
â”‚                                 â”‚  â€¢ Statistics display                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

""")

def print_example_content():
    """Show example content from actual files."""
    print("ðŸ“ SAMPLE FILE CONTENT ANALYSIS")
    print("=" * 80)

    from html_indexer import HtmlIndexer

    indexer = HtmlIndexer('Jan.zip')
    indexer.build_index()

    # Show content of a sample file
    import zipfile
    with zipfile.ZipFile('Jan.zip', 'r') as zip_ref:
        # Get a small file to show
        for file_info in zip_ref.infolist():
            if file_info.filename == 'Jan/bill.html':
                with zip_ref.open(file_info) as html_file:
                    content = html_file.read().decode('utf-8', errors='ignore')

                print(f"\nðŸ“„ Raw HTML Content (Jan/bill.html):")
                print("-" * 50)
                print(content[:500] + "..." if len(content) > 500 else content)

                print(f"\nðŸ” Extracted Words:")
                print("-" * 50)
                words, positions = indexer.extract_words_with_positions(content)
                print(f"Total words after filtering: {len(words)}")
                print(f"First 20 words: {words[:20]}")

                print(f"\nðŸ“ Word Positions (sample):")
                print("-" * 50)
                for word in ['web', 'page', 'home'][:3]:
                    if word in positions:
                        print(f"'{word}': positions {positions[word]}")

                print(f"\nðŸ”— Extracted URLs:")
                print("-" * 50)
                urls = indexer.extract_urls_from_html(content)
                for url in urls[:5]:
                    print(f"  â€¢ {url}")
                if len(urls) > 5:
                    print(f"  ... and {len(urls) - 5} more URLs")

                break

if __name__ == "__main__":
    print_data_structure_diagram()
    print_example_content()